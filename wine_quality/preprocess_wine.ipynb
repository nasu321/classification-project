{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e59b667",
   "metadata": {},
   "source": [
    "# Wine Quality â€” Preprocessing Notebook\n",
    "\n",
    "Step-by-step preprocessing for `/mnt/data/wine-quality.csv` with short explanations. Run cells sequentially."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d910a69",
   "metadata": {},
   "source": [
    "## 1) Imports\n",
    "\n",
    "Import libraries used for data handling, preprocessing and saving outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98475af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "print('Libraries imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af25324a",
   "metadata": {},
   "source": [
    "## 2) Load dataset\n",
    "\n",
    "Read the CSV file into a DataFrame and show shape & first rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64703623",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/mnt/data/wine-quality.csv'\n",
    "\n",
    "assert os.path.exists(DATA_PATH), f\"File not found: {DATA_PATH}\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print('Shape:', df.shape)\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a59696",
   "metadata": {},
   "source": [
    "## 3) Info & basic statistics\n",
    "\n",
    "Check column types and summary statistics to understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe8d53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame info\n",
    "print('\\nInfo:')\n",
    "df.info()\n",
    "\n",
    "# Describe numeric columns\n",
    "print('\\nDescribe:')\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c12da00",
   "metadata": {},
   "source": [
    "## 4) Missing values\n",
    "\n",
    "Identify any missing values per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4bcddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Missing values per column:')\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcf0c8d",
   "metadata": {},
   "source": [
    "## 5) Duplicate rows\n",
    "\n",
    "Check and optionally remove exact duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857e52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_count = df.duplicated().sum()\n",
    "print('Duplicate rows:', dup_count)\n",
    "if dup_count > 0:\n",
    "    df = df.drop_duplicates().reset_index(drop=True)\n",
    "    print('Dropped duplicates. New shape:', df.shape)\n",
    "else:\n",
    "    print('No duplicates to drop')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7958200e",
   "metadata": {},
   "source": [
    "## 6) Column types\n",
    "\n",
    "Separate numeric and non-numeric columns for later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e5b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "non_numeric_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "print('Numeric columns:', numeric_cols)\n",
    "print('Non-numeric columns:', non_numeric_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f52116",
   "metadata": {},
   "source": [
    "## 7) Imputation\n",
    "\n",
    "Impute numeric columns with the median and categorical with the most frequent value (if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8acedfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.isna().sum().sum() == 0:\n",
    "    print('No missing values to impute')\n",
    "else:\n",
    "    num_imp = SimpleImputer(strategy='median')\n",
    "    cat_imp = SimpleImputer(strategy='most_frequent')\n",
    "    if numeric_cols:\n",
    "        df[numeric_cols] = num_imp.fit_transform(df[numeric_cols])\n",
    "    if non_numeric_cols:\n",
    "        df[non_numeric_cols] = cat_imp.fit_transform(df[non_numeric_cols])\n",
    "    print('Imputation complete. Remaining missing:', df.isna().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db759175",
   "metadata": {},
   "source": [
    "## 8) Outlier check (IQR method)\n",
    "\n",
    "Count potential outliers per numeric column using IQR. This just reports counts; you can decide to remove/winsorize later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed659b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_counts = {}\n",
    "for c in numeric_cols:\n",
    "    Q1 = df[c].quantile(0.25)\n",
    "    Q3 = df[c].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    outlier_counts[c] = int(((df[c] < lower) | (df[c] > upper)).sum())\n",
    "\n",
    "import pandas as pd\n",
    "pd.Series(outlier_counts).sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb74c05",
   "metadata": {},
   "source": [
    "## 9) Target handling\n",
    "\n",
    "If 'quality' column exists we create a binary target `quality_binary` (quality >= 7 -> 1). Otherwise we'll use 'quality' or the last column as target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03459f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'quality' in df.columns:\n",
    "    print(\"Found 'quality' column. Value counts:\\n\", df['quality'].value_counts().sort_index())\n",
    "    df['quality_binary'] = (df['quality'] >= 7).astype(int)\n",
    "    target = 'quality_binary'\n",
    "    print(\"Created 'quality_binary' as target (quality >= 7 => 1).\")\n",
    "else:\n",
    "    target = 'quality' if 'quality' in df.columns else df.columns[-1]\n",
    "    print('Using target column:', target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab024ea",
   "metadata": {},
   "source": [
    "## 10) Encoding categorical variables\n",
    "\n",
    "One-hot encode non-numeric columns (drop_first=True to avoid multicollinearity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb018ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if non_numeric_cols:\n",
    "    df = pd.get_dummies(df, columns=non_numeric_cols, drop_first=True)\n",
    "    print('One-hot encoding applied. New shape:', df.shape)\n",
    "else:\n",
    "    print('No categorical columns to encode')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0156c52c",
   "metadata": {},
   "source": [
    "## 11) Feature / target split\n",
    "\n",
    "Separate X and y for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1553cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "print('X shape:', X.shape)\n",
    "print('y distribution:')\n",
    "print(y.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea853201",
   "metadata": {},
   "source": [
    "## 12) Train-test split\n",
    "\n",
    "Split into train and test sets. Stratify when the target is categorical to preserve label proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee1efca",
   "metadata": {},
   "outputs": [],
   "source": [
    "stratify_arg = y if (y.dtype.kind in 'i' and y.nunique() <= 20) else None\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=stratify_arg\n",
    ")\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1e76e2",
   "metadata": {},
   "source": [
    "## 13) Scaling numeric features\n",
    "\n",
    "Fit `StandardScaler` on training numeric features and transform both train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae12778",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_after = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print('Numeric features to scale:', numeric_after)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_num = pd.DataFrame(scaler.fit_transform(X_train[numeric_after]), columns=numeric_after, index=X_train.index)\n",
    "X_test_num  = pd.DataFrame(scaler.transform(X_test[numeric_after]), columns=numeric_after, index=X_test.index)\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[numeric_after] = X_train_num\n",
    "X_test_scaled[numeric_after] = X_test_num\n",
    "\n",
    "X_train_scaled.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d512cb",
   "metadata": {},
   "source": [
    "## 14) Save preprocessed datasets & scaler\n",
    "\n",
    "Save train/test CSVs and the fitted scaler for later modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0231a954",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = '/mnt/data/preprocessed_wine'\n",
    "import os\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "train_df = X_train_scaled.copy()\n",
    "train_df[target] = y_train\n",
    "\n",
    "test_df = X_test_scaled.copy()\n",
    "test_df[target] = y_test\n",
    "\n",
    "train_path = os.path.join(OUT_DIR, 'wine_train_preprocessed.csv')\n",
    "test_path  = os.path.join(OUT_DIR, 'wine_test_preprocessed.csv')\n",
    "scaler_path = os.path.join(OUT_DIR, 'standard_scaler.joblib')\n",
    "\n",
    "train_df.to_csv(train_path, index=False)\n",
    "test_df.to_csv(test_path, index=False)\n",
    "joblib.dump(scaler, scaler_path)\n",
    "\n",
    "print('Saved files:')\n",
    "print('-', train_path)\n",
    "print('-', test_path)\n",
    "print('-', scaler_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4a3e20",
   "metadata": {},
   "source": [
    "## 15) Quick summary\n",
    "\n",
    "Final quick stats about preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7710b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    'original_shape': df.shape,\n",
    "    'train_shape': X_train.shape,\n",
    "    'test_shape': X_test.shape,\n",
    "    'num_numeric_features': len(numeric_after),\n",
    "    'target': target,\n",
    "}\n",
    "summary\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
